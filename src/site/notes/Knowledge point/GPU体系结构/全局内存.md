---
{"dg-publish":true,"tags":["GPU体系结构"],"permalink":"/Knowledge point/GPU体系结构/全局内存/","dgPassFrontmatter":true}
---

下图展示了CUDA 内存模型的层次结构，每一种都有不同的作用域、生命周期以及缓存行为。
![Pasted image 20240513143535.png](/img/user/Knowledge%20point/imgs/Pasted%20image%2020240513143535.png)
### 全局内存
全局内存是GPU中最大、延迟最高、最长使用的内存，通常说的“显存”中的大部分都是全局内存。全局内存的声明可以在任何SM设备上被访问到，并且贯穿应用程序的整个生命周期。
全局内存的主要角色是为核函数提供数据，并在主机与设备及设备与设备之间传递数据。可以用 `cudaMemcpy`函数将主机的数据复制到全局内存，或者反过来。 如将中 M 字节的数据从主机复制到设备，操作如下：
```text
cudaMemcpy(d_x, h_x, M, cudaMemcpyHostToDevice);
```
全局内存变量可以被静态声明和动态声明， 如 静态全局内存变量由以下方式在任何函数外部定义 ：
```text
__device__ T x; // 单个变量 
__device__ T y[N]; // 固定长度的数组
```
后续将会重点研究如何优化全局内存访问，以及如何提高全局内存的数据吞吐率。